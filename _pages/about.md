---
layout: about
title: about
permalink: /
# subtitle: <a href='#'>Affiliations</a>. Address. Contacts. Moto. Etc.

profile:
  align: center
  image: atli_kosson.jpg
  image_circular: false # crops the image to make it circular
  # more_info: >
  #   <p>555 your office number</p>
  #   <p>123 your address street</p>
  #   <p>Your City, State 12345</p>

news: true  # includes a list of news items
latest_posts: false  # includes a list of the newest posts
selected_papers: false # includes a list of papers marked as "selected={true}"
social: false  # includes social icons at the bottom of the page
---
**Short Bio:** I am a third-year computer science PhD student at EPFL in SwitzerlandðŸ‡¨ðŸ‡­ supervised by [Professor Martin Jaggi](https://people.epfl.ch/martin.jaggi). Previously, I worked as an Autopilot Engineer at [Tesla](https://www.tesla.com/autopilot) optimizing large-scale neural network training and as an ML Research Engineer at [Cerebras](https://cerebras.net) on efficient training algorithms. I did my Master's at Stanford University and my undergrad at the University of Iceland ðŸ‡®ðŸ‡¸ where I grew up.

**Research Focus:** I am broadly interested in improving our understanding of neural network architectures, internal representations, and optimization. Although my focus is on understanding, I lean towards the "top-down" style of experimentation and applied analysis instead of a "bottom-up" theoretical approach. Currently, I am investigating how and why optimization tricks like weight decay and adaptive learning rates aid training.
